{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kH16rnZ7wt_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtssFUKb-jqx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4A84rlfDA23",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8OLDR79DrHG",
        "outputId": "dcc0f43e-0854-4244-d99e-bf5dc3afd7f1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n"
          ]
        }
      ],
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQL3H6RJL3h"
      },
      "source": [
        "# The model\n",
        "Let's start with the model we first saw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FXQlB9kH1ov",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from models import model_v3 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo"
      },
      "source": [
        "# Model Params\n",
        "Can't emphasize on how important viewing Model Summary is.\n",
        "Unfortunately, there is no in-built model visualizer, so we have to take external help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5skB97zIJQQe",
        "outputId": "c0edb4b4-0640-4c9a-c497-07d7e5246182",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             144\n",
            "              ReLU-2           [-1, 16, 26, 26]               0\n",
            "       BatchNorm2d-3           [-1, 16, 26, 26]              32\n",
            "            Conv2d-4           [-1, 20, 24, 24]           2,880\n",
            "              ReLU-5           [-1, 20, 24, 24]               0\n",
            "       BatchNorm2d-6           [-1, 20, 24, 24]              40\n",
            "            Conv2d-7           [-1, 10, 24, 24]             200\n",
            "         MaxPool2d-8           [-1, 10, 12, 12]               0\n",
            "            Conv2d-9           [-1, 10, 12, 12]             900\n",
            "             ReLU-10           [-1, 10, 12, 12]               0\n",
            "      BatchNorm2d-11           [-1, 10, 12, 12]              20\n",
            "          Dropout-12           [-1, 10, 12, 12]               0\n",
            "           Conv2d-13           [-1, 10, 12, 12]             900\n",
            "             ReLU-14           [-1, 10, 12, 12]               0\n",
            "      BatchNorm2d-15           [-1, 10, 12, 12]              20\n",
            "           Conv2d-16           [-1, 10, 10, 10]             900\n",
            "             ReLU-17           [-1, 10, 10, 10]               0\n",
            "      BatchNorm2d-18           [-1, 10, 10, 10]              20\n",
            "          Dropout-19           [-1, 10, 10, 10]               0\n",
            "        MaxPool2d-20             [-1, 10, 5, 5]               0\n",
            "           Conv2d-21             [-1, 20, 3, 3]           1,800\n",
            "             ReLU-22             [-1, 20, 3, 3]               0\n",
            "      BatchNorm2d-23             [-1, 20, 3, 3]              40\n",
            "AdaptiveAvgPool2d-24             [-1, 20, 1, 1]               0\n",
            "           Conv2d-25             [-1, 10, 1, 1]             200\n",
            "================================================================\n",
            "Total params: 8,096\n",
            "Trainable params: 8,096\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.68\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.71\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = model_v3().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3"
      },
      "source": [
        "# Training and Testing\n",
        "\n",
        "All right, so we have 24M params, and that's too many, we know that. But the purpose of this notebook is to set things right for our future experiments.\n",
        "\n",
        "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs.\n",
        "\n",
        "Let's write train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbkF2nN_LYIb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from utils import train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXfXxHNlTZvR",
        "outputId": "a4c4d44b-95ee-4ead-e90e-927e69757d20",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.10085026174783707 Batch_id=468 Accuracy=91.19: 100%|██████████| 469/469 [00:26<00:00, 17.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0621, Accuracy: 9826/10000 (98.26%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.03887877240777016 Batch_id=468 Accuracy=98.03: 100%|██████████| 469/469 [00:22<00:00, 20.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0432, Accuracy: 9874/10000 (98.74%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.0618673674762249 Batch_id=468 Accuracy=98.43: 100%|██████████| 469/469 [00:22<00:00, 20.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0370, Accuracy: 9881/10000 (98.81%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.11553207039833069 Batch_id=468 Accuracy=98.75: 100%|██████████| 469/469 [00:21<00:00, 21.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0437, Accuracy: 9863/10000 (98.63%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.10878857225179672 Batch_id=468 Accuracy=98.78: 100%|██████████| 469/469 [00:21<00:00, 21.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0329, Accuracy: 9904/10000 (99.04%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.06395141780376434 Batch_id=468 Accuracy=98.89: 100%|██████████| 469/469 [00:21<00:00, 21.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0281, Accuracy: 9915/10000 (99.15%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.03760405629873276 Batch_id=468 Accuracy=98.98: 100%|██████████| 469/469 [00:21<00:00, 21.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0294, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.04193821921944618 Batch_id=468 Accuracy=99.05: 100%|██████████| 469/469 [00:22<00:00, 21.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0277, Accuracy: 9915/10000 (99.15%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.043630387634038925 Batch_id=468 Accuracy=99.12: 100%|██████████| 469/469 [00:21<00:00, 21.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0309, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.06975232809782028 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:22<00:00, 20.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0239, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.046166181564331055 Batch_id=468 Accuracy=99.15: 100%|██████████| 469/469 [00:23<00:00, 19.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.007830402813851833 Batch_id=468 Accuracy=99.13: 100%|██████████| 469/469 [00:22<00:00, 20.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0243, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.006819351110607386 Batch_id=468 Accuracy=99.25: 100%|██████████| 469/469 [00:22<00:00, 20.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.06264819949865341 Batch_id=468 Accuracy=99.23: 100%|██████████| 469/469 [00:22<00:00, 20.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0210, Accuracy: 9932/10000 (99.32%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.0030536248814314604 Batch_id=468 Accuracy=99.29: 100%|██████████| 469/469 [00:22<00:00, 20.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0235, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.05123462900519371 Batch_id=468 Accuracy=99.27: 100%|██████████| 469/469 [00:23<00:00, 20.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0202, Accuracy: 9941/10000 (99.41%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model =  model_v3().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "\n",
        "EPOCHS = 16\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # scheduler.step()\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Target :- \n",
        "**1. Add Augmentation** \n",
        "\n",
        "**2. Results :**\n",
        "\n",
        "        1. Parameters : 8K\n",
        "        2. Best Train Accuracy : 99.29 %\n",
        "        3. Best Test Accuracy : 99.41% (15th epoch)\n",
        "\n",
        "**3. Analysis :**\n",
        "\n",
        "        1. Model has ran for 15 epochs\n",
        "        2. Since model was underfitting and training accuracy was not increasing so removed almost 90% of the dropout layers and were able to achieve good accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKeBz_bFDIBd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
